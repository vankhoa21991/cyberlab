{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce46090-85df-4f2d-97fe-759c0fb5cf47",
   "metadata": {},
   "source": [
    "# Phân loại chó và mèo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bed17f",
   "metadata": {},
   "source": [
    "Trong bài này, ta sẽ xây dựng mô hình CNN để phân biệt ảnh của lớp chó và lớp mèo. Đầu tiên ta cần tải dataset từ Kaggle về sử dụng [link](https://www.kaggle.com/c/dogs-vs-cats/data). Chú ý cần phải đăng ký tài khoản trên trang kaggle để có thể tải dữ liệu. Sau khi tải về ta giải nén ra thư mục như sau:\n",
    "\n",
    "    -dogs-vs-cats\n",
    "        -train\n",
    "            -cat.0.jpg\n",
    "            -dog.0.jpg\n",
    "        -test1\n",
    "            -cat.1000.jpg\n",
    "            -dog.1000.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78415cce",
   "metadata": {},
   "source": [
    "Khi giải quyết một vấn đề, điều đầu tiên ta nên phân loại vấn đề vô một nhóm, từ đó mới đưa ra cách giải quyết phù hợp. Bài toán này là bài toán phân loại ảnh, nghĩa là input là ảnh (ma trận), và output là class chó hoặc mèo, tức là phân loại nhị phân (binary classification). Có nhiều cách giải quyết vấn đề này, ví dụ như trải phẳng ảnh ra thành vector, rồi sử dụng MLP với lớp sau cùng là 2 neuron, cách này đã được phân tích trong phần bài giảng. \n",
    "\n",
    "Trong bài tập này, ta sẽ xây dựng mô hình CNN để giải quyết bài toán."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b13efd",
   "metadata": {},
   "source": [
    "## Phân tích dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f7eb6d",
   "metadata": {},
   "source": [
    "Đối với dữ liệu hình ảnh, ta nên tìm cách trả lời những câu hỏi:\n",
    "- Có bao nhiêu điểm dữ liệu cho mỗi class\n",
    "- Mỗi điểm dữ liệu trông như thế nào, có gì đặc biệt\n",
    "- Kích thước ảnh có quá chênh lệch không\n",
    "- ...\n",
    "\n",
    "Để trả lời những câu hỏi này, ta phải phân tích dữ liệu trước khi xây dựng mô hình, đây là bước rất quan trọng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a04e31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset_dir = 'D:\\\\datasets\\\\dogs-vs-cats\\\\train'\n",
    "base_dir = 'D:\\\\datasets\\\\dogs-vs-cats\\\\preprocess'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e6e01",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da8415d",
   "metadata": {},
   "source": [
    "## Xây dựng class cung cấp dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a55e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d469a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "img_dimensions = 224\n",
    "\n",
    "# Normalize to the ImageNet mean and standard deviation\n",
    "# Could calculate it for the cats/dogs data set, but the ImageNet\n",
    "# values give acceptable results here.\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions, img_dimensions)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "img_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_dimensions,img_dimensions)),    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )\n",
    "    ])\n",
    "\n",
    "def check_image(path):\n",
    "    try:\n",
    "        im = Image.open(path)\n",
    "        return True\n",
    "    except:\n",
    "        print(path)\n",
    "        return False\n",
    "\n",
    "train_data_path = \"D:\\\\datasets\\\\dogs-vs-cats\\\\preprocess\\\\train\"\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms, is_valid_file=check_image)\n",
    "\n",
    "validation_data_path = \"D:\\\\datasets\\\\dogs-vs-cats\\\\preprocess\\\\validation\"\n",
    "validation_data = torchvision.datasets.ImageFolder(root=validation_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "\n",
    "test_data_path = \"D:\\\\datasets\\\\dogs-vs-cats\\\\preprocess\\\\test\"\n",
    "test_data = torchvision.datasets.ImageFolder(root=test_data_path,transform=img_test_transforms, is_valid_file=check_image)\n",
    "\n",
    "num_workers = 6\n",
    "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3f5dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device=\"cpu\"):\n",
    "    print(device)\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            output = model(inputs)\n",
    "            loss = loss_fn(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item() * inputs.size(0)\n",
    "        training_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        num_correct = 0 \n",
    "        num_examples = 0\n",
    "        for batch in tqdm(val_loader):\n",
    "            inputs, targets = batch\n",
    "            inputs = inputs.to(device)\n",
    "            output = model(inputs)\n",
    "            targets = targets.to(device)\n",
    "            loss = loss_fn(output,targets) \n",
    "            valid_loss += loss.data.item() * inputs.size(0)\n",
    "                        \n",
    "            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)\n",
    "            num_correct += torch.sum(correct).item()\n",
    "            num_examples += correct.shape[0]\n",
    "        valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,\n",
    "        valid_loss, num_correct / num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb189d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data_loader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('correct: {:d}  total: {:d}'.format(correct, total))\n",
    "    print('accuracy = {:f}'.format(correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec8fcfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all params except the BatchNorm layers, as here they are trained to the\n",
    "# mean and standard deviation of ImageNet and we may lose some signal\n",
    "for name, param in model_resnet18.named_parameters():\n",
    "    if(\"bn\" not in name):\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Replace the classifier\n",
    "num_classes = 2\n",
    "\n",
    "model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),\n",
    "                                  nn.ReLU(),\n",
    "                                  nn.Dropout(),\n",
    "                                  nn.Linear(512, num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3478f99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:38<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 0.0878, Validation Loss: 0.0660, accuracy = 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:30<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.0494, Validation Loss: 0.0328, accuracy = 0.9873\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model_resnet18.to(device)\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)\n",
    "train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa070fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 4435  total: 4500\n",
      "accuracy = 0.985556\n"
     ]
    }
   ],
   "source": [
    "test_model(model_resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810b6db",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f05f0a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogs\n",
      "cats\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def find_classes(dir):\n",
    "    classes = os.listdir(dir)\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "def make_prediction(model, filename):\n",
    "    labels, _ = find_classes('D:\\\\datasets\\\\dogs-vs-cats\\\\preprocess/test')\n",
    "    img = Image.open(filename)\n",
    "    img = img_test_transforms(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    prediction = model(img.to(device))\n",
    "    prediction = prediction.argmax()\n",
    "    print(labels[prediction])\n",
    "    \n",
    "make_prediction(model_resnet18, 'D:\\\\datasets\\\\dogs-vs-cats\\\\preprocess\\\\test/dogs/dog.11460.jpg')\n",
    "make_prediction(model_resnet18, 'D:\\\\datasets\\\\dogs-vs-cats\\\\preprocess\\\\test/cats/cat.12262.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_resnet18.state_dict(), \"./model_resnet18.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560d216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
