{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"RaCd8gijXzGh"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"colab_type":"code","executionInfo":{"elapsed":9111,"status":"ok","timestamp":1592016299596,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"aJrbEADxYWy5","outputId":"81a30e47-f0d5-495c-8158-b0d2a27febc8"},"outputs":[],"source":["# Load Cifar-10 data-set\n","(train_im, train_lab), (test_im, test_lab) = tf.keras.datasets.cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","executionInfo":{"elapsed":1409,"status":"ok","timestamp":1592016308097,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"F2RBRZoeYvDN","outputId":"9b21dee7-c308-4dfb-b424-e8bd1da62f11"},"outputs":[],"source":["#### Normalize the images to pixel values (0, 1)\n","train_im, test_im = train_im/255.0 , test_im/255.0\n","#### Check the format of the data \n","print (\"train_im, train_lab types: \", type(train_im), type(train_lab))\n","#### check the shape of the data\n","print (\"shape of images and labels array: \", train_im.shape, train_lab.shape) \n","print (\"shape of images and labels array ; test: \", test_im.shape, test_lab.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208},"colab_type":"code","executionInfo":{"elapsed":1458,"status":"ok","timestamp":1591671861430,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"utISMeH0YzRQ","outputId":"60420f61-ac82-4856-e508-6ea88fca8029"},"outputs":[],"source":["#### Check the distribution of unique elements \n","(unique, counts) = np.unique(train_lab, return_counts=True)\n","\n","frequencies = np.asarray((unique, counts)).T\n","\n","print (frequencies)\n","print (len(unique))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":729},"colab_type":"code","executionInfo":{"elapsed":1765,"status":"ok","timestamp":1592016314029,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"xFG1egg_Y3s8","outputId":"73268b89-2bd4-49a8-bdf1-058f2b8d4455"},"outputs":[],"source":["class_types = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n","               'dog', 'frog', 'horse', 'ship', 'truck'] # from cifar-10 website\n","\n","plt.figure(figsize=(10,10))\n","for i in range(12):\n","    plt.subplot(4,3,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_im[i], cmap='gray')\n","    plt.xlabel(class_types[train_lab[i][0]], fontsize=13)\n","plt.tight_layout()    \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"VLm-3o3JZDNH"},"outputs":[],"source":["### One hot encoding for labels \n","\n","train_lab_categorical = tf.keras.utils.to_categorical(\n","    train_lab, num_classes=10, dtype='uint8')\n","\n","test_lab_categorical = tf.keras.utils.to_categorical(\n","    test_lab, num_classes=10, dtype='uint8')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"colab_type":"code","executionInfo":{"elapsed":2107,"status":"ok","timestamp":1592016319146,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"vxqmhQPSZzCv","outputId":"131db0c8-9a5c-41fd-94ae-1ee712b8a436"},"outputs":[],"source":["### Train -test split \n","\n","from sklearn.model_selection import train_test_split \n","train_im, valid_im, train_lab, valid_lab = train_test_split(train_im, train_lab_categorical, test_size=0.20, \n","                                                            stratify=train_lab_categorical, \n","                                                            random_state=40, shuffle = True)\n","\n","print (\"train data shape after the split: \", train_im.shape)\n","print ('new validation data shape: ', valid_im.shape)\n","print (\"validation labels shape: \", valid_lab.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"LjGvpnx1ay-P"},"outputs":[],"source":["#### Necessary Imports for Neural Net \n","\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n","     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add \n","from tensorflow.keras.models import Model\n","from tensorflow.keras import activations\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.regularizers import l2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"o1tLwFBEZ7Oj"},"outputs":[],"source":["##### Include Little Data Augmentation \n","batch_size = 64 # try several values\n","\n","train_DataGen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.2, \n","                                                                width_shift_range=0.1, \n","                                                                height_shift_range = 0.1, \n","                                                                horizontal_flip=True)\n"," \n","valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n","\n","train_set_conv = train_DataGen.flow(train_im, train_lab, batch_size=batch_size) # train_lab is categorical \n","valid_set_conv = valid_datagen.flow(valid_im, valid_lab, batch_size=batch_size) # so as valid_lab "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OvyzKxBta4Cw"},"source":["For more read check the original [Residual Net paper](https://arxiv.org/pdf/1512.03385.pdf). \n","\n","Then main idea is to train a very deep netowrk without degradation. \n","\n","Let's describe the Residual block in short. Below is a simplified picture-- \n","![resnet](https://drive.google.com/uc?id=1eSstMpN_x05-A_ScoUfx12fMU1Fcjvtj)\n","\n","Why Resnet work? \n","\n","Below is Andrew Ng's explanation : \n","\n","Consider the activation function of layer l is $a^{[l]}$. In general in a node first we apply a linear operation (depending upon the layer weights and biases) and then apply the non-linearity (sigmoid, tanh, Relu etc.) operator. To write it in more simple terms, with reference to the figure -- \n","\n","$Z^{[l + 1]} = W^{[l + 1]}\\, a^{[l]} + b^{[l+1]};\\, a^{[l + 1]} = g\\left(Z^{[l + 1]} \\right)$ ... (1)\n","\n","$Z^{[l + 2]} = W^{[l + 2]}\\, a^{[l + 1]} + b^{[l+2]};\\, a^{[l + 2]} = g\\left(Z^{[l + 2]} \\right)$ ... (2)\n","\n","Including the Skip connection the activation $a^{[l]}$ will be sent (copied) much further into the network and add before applying the non-linearity. Let's see how the second equation changes in Resnet-- \n","\n","$Z^{[l + 2]} = W^{[l + 2]}\\, a^{[l + 1]} + b^{[l+2]};\\, a^{[l + 2]} = g\\left(Z^{[l + 2]} + a^{[l]} \\right)$ ...(3). \n","\n","The idea is to take many such resnet block and stack them together. The reason we can increase the depth of the network with training error continulously going down in resnet is becasue of the identity blocks. In equation 3, assuming L2 regularization, we can see that weights and biases would shrink (go close to zero) and thus $a^{[l+2]} = g(\\sim 0+a^{[l]})$. With relu non-linearity function this would be $a^{[l+2]} \\approx a^{[l]}$. Thus going deep doesn't hurt the performance as learning the identity function is easy and, in the process we can learn some more important features.  "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DxTVSW18iQMD"},"source":["### Residual Block and Resnet :"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"r4pJ-93dPCQa"},"source":["Let's deep dive to learn the ingenious idea behind the proposal of ResNet by K.He. et.al. For more details always check the original paper. \n","\n","The main motivation of the work is to address the degradation problem in deep network. Adding more layers to a sufficiently deep neural network would first see a saturation in accuracy and then the accuracy degrades. He et.al. presented the following picture of train and test error with Cifar-10 data-set using vanilla net-- \n","![resnet_degradation](https://drive.google.com/uc?id=1jAqwXV01_nRTH1g6L9aZe2m1pPPHZosn)\n","\n","As the figure shows [reference: [Resnet paper](https://arxiv.org/pdf/1512.03385.pdf)] going deeper eventually worsens the performance of the network on the data-set. \n","\n","Another way of thinking about this problem is to consider a sufficiently deeper network calculates strong set of features needed for the task in hand (ex: image classification). If we add one more layer to this network what would happen? Before the addition if the model could already calculate some strong features then the added layer should be able to just copy the features i.e. perform an identity mapping, which seems to be a very simple task but it is far from reality. \n","\n","Let's understand this via some simple mathematical concepts. \n","Consider a DNN architecture including learning rate and other hyperparameter that can reach a class of functions $\\mathcal F$. So for all $f \\in \\mathcal F$ there exist some sort of parameters $W$ which can be obtained after training with some particular data-set. If $f^*$ is the function we would really like to find but if it is not in $\\mathcal F$ then we try to find $f_{\\mathcal F}^*$ within $\\mathcal F$. \n","\n","It would be reasonable to assume if we design a powerful architecture $\\mathcal F_1$, we should arrive at a better outcome i.e. $f_{\\mathcal F_1}^*$ is better than $f_{\\mathcal F}^*$. But if $\\mathcal F \\nsubseteq \\mathcal {F_1}$, then there is no guarantee that this should happen. In fact, $f_{\\mathcal F_1}$ may be even worse. This is actually the degradation problem and what we encounter in real life.\n","\n","So main point is only if the complex and deeper neural net function classes contain the simpler and shallower ones, then we can guarantee that the deeper network will increase the expressive power of the network.     "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GzyAgPuSNKph"},"source":["### Residual Block "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XEkRrqPJO0WU"},"source":["The main building block of the ResNet are the residual blocks. The framework strictly stems from the previous ideas discussed. \n","\n","If we consider $x$ as input and the desired mapping from input to output is denoted by $g(x)$. We stack layers (including non-linearity coming from the activation function) to fit a different function $f(x) : = g(x) - x $. The original mapping is then recast to $f(x) + x$. He et.al. hypothesized that it is easier to optimize the residual $(f)$ than the original mapping $(g)$. The basic residual block is shown below --\n","![residual_block](https://drive.google.com/uc?id=1HvMABUULlzJ9WS8jrhN9uaJIM71l0tyV)\n","\n","One more important point to remember is about the dimension of the input $x$ and output $f(x)$. The building block can usually be defined as -- \n","$y = f(x, \\{W_i\\}) + x$; \n","\n","and the network learns the residual mapping $f$. In the figure above there are 2 weight layers and an activation function in between in the residual block.  So $f = W_2\\sigma (W_1x)$. Then $f+x$ is performed by elementwise addition. The skip/shortcut connection doesn't use any additional parameters. The dimesion of $f$ and $x$ must be equal, if this is not the case, then one can perform a linear projection $W_s$  by shortcut connection to match dimension. A square matrix $W_s$ can also be used ($y = f(x, \\{W_i\\}) + W_sx $) but the authors suggested that the identity conncection is sufficient to address the degradation problem. \n","\n","With all these in mind, let's implement ResNet. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nQDjDqzscv-q"},"source":["### Build ResNet with TensorFlow \n","\n","I applied the activation after the batch norm but this is actually highly debatable on where to apply batch norm, before or after the activation layer. Here's a [stack post](https://stackoverflow.com/questions/39691902/ordering-of-batch-normalization-and-dropout) on the topic.  Also instead of a 2 block skip connection we will use 3 block skip connection (discussed later). \n","Let's just briefly some other important points related to the original resnet architecture, below is a picture of He et.al. paper --\n","![res_arch](https://drive.google.com/uc?id=1y2JUXhfuSAK0QFOHWJhmpToZnHkNa1lW)  \n","\n","Dimension remains same in solid line shortcuts and increases for dotted lines. \n","\n","The identity shorcut connections are directly used when input and output are of same dimensions. But when the dimensions are different the authors considered two options--\n","\n","* Skip connection performs identity mapping but use zero padding for increased dimension. So no extra paramter added. \n","* The projection shortcut (including matrix $W_s$ in the equation above) used to match dimension by $1\\times 1 $ convlolutions. For both options when the shortcuts go across 2 feature maps of 2 sizes, they are performed with strides of 2.     \n","\n","We will be working with a rather deep resnet-- 50 layers and we will follow the method authors described. For 50/100/150 layers authors used 3 blocks skip connection, as shown in the picture below-- \n","![res50net](https://drive.google.com/uc?id=1k9fbtyQgCV1kD9IFjIeQFws58K8Pg4-6) \n","\n","The stacked 3 layers have filters $1\\times 1, 3\\times 3, 1\\times 1$, where $1\\times 1$ layers increase and decrease the dimension and $3\\times 3$ layer acts as bottleneck with smaller input/output dimensions. As can be seen in the original resnet structure after the first pooling there's no pooling layer. So the dimension reduction is happening via $1\\times 1$ convolution with strides 2.    \n","\n","With the above picture and the important info let's build the architecture.   "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"D6_kNNzvp5-_"},"outputs":[],"source":["def res_identity(x, filters): \n","  ''' renet block where dimension doesnot change.\n","  The skip connection is just simple identity conncection\n","  we will have 3 blocks and then input will be added\n","  '''\n","  x_skip = x # this will be used for addition with the residual block \n","  f1, f2 = filters\n","\n","  #first block \n","  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n","  x = BatchNormalization()(x)\n","  x = Activation(activations.relu)(x)\n","\n","  #second block # bottleneck (but size kept same with padding)\n","  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n","  x = BatchNormalization()(x)\n","  x = Activation(activations.relu)(x)\n","\n","  # third block activation used after adding the input\n","  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n","  x = BatchNormalization()(x)\n","  # x = Activation(activations.relu)(x)\n","\n","  # add the input \n","  x = Add()([x, x_skip])\n","  x = Activation(activations.relu)(x)\n","\n","  return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"7oMQ2Qg8oA_G"},"outputs":[],"source":["def res_conv(x, s, filters):\n","  '''\n","  here the input size changes, when it goes via conv blocks\n","  so the skip connection uses a projection (conv layer) matrix\n","  ''' \n","  x_skip = x\n","  f1, f2 = filters\n","\n","  # first block\n","  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x)\n","  # when s = 2 then it is like downsizing the feature map\n","  x = BatchNormalization()(x)\n","  x = Activation(activations.relu)(x)\n","\n","  # second block\n","  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n","  x = BatchNormalization()(x)\n","  x = Activation(activations.relu)(x)\n","\n","  #third block\n","  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n","  x = BatchNormalization()(x)\n","\n","  # shortcut \n","  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n","  x_skip = BatchNormalization()(x_skip)\n","\n","  # add \n","  x = Add()([x, x_skip])\n","  x = Activation(activations.relu)(x)\n","\n","  return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"DKngMdcEJEdI"},"outputs":[],"source":["### Combine the above functions to build 50 layers resnet. \n","def resnet50():\n","\n","  input_im = Input(shape=(train_im.shape[1], train_im.shape[2], train_im.shape[3])) # cifar 10 images size\n","  x = ZeroPadding2D(padding=(3, 3))(input_im)\n","\n","  # 1st stage\n","  # here we perform maxpooling, see the figure above\n","\n","  x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n","  x = BatchNormalization()(x)\n","  x = Activation(activations.relu)(x)\n","  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","\n","  #2nd stage \n","  # frm here on only conv block and identity block, no pooling\n","\n","  x = res_conv(x, s=1, filters=(64, 256))\n","  x = res_identity(x, filters=(64, 256))\n","  x = res_identity(x, filters=(64, 256))\n","\n","  # 3rd stage\n","\n","  x = res_conv(x, s=2, filters=(128, 512))\n","  x = res_identity(x, filters=(128, 512))\n","  x = res_identity(x, filters=(128, 512))\n","  x = res_identity(x, filters=(128, 512))\n","\n","  # 4th stage\n","\n","  x = res_conv(x, s=2, filters=(256, 1024))\n","  x = res_identity(x, filters=(256, 1024))\n","  x = res_identity(x, filters=(256, 1024))\n","  x = res_identity(x, filters=(256, 1024))\n","  x = res_identity(x, filters=(256, 1024))\n","  x = res_identity(x, filters=(256, 1024))\n","\n","  # 5th stage\n","\n","  x = res_conv(x, s=2, filters=(512, 2048))\n","  x = res_identity(x, filters=(512, 2048))\n","  x = res_identity(x, filters=(512, 2048))\n","\n","  # ends with average pooling and dense connection\n","\n","  x = AveragePooling2D((2, 2), padding='same')(x)\n","\n","  x = Flatten()(x)\n","  x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n","\n","  # define the model \n","\n","  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n","\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"AzP_9hapzMPx"},"outputs":[],"source":["### Define some Callbacks\n","def lrdecay(epoch):\n","    lr = 1e-3\n","    if epoch > 180:\n","        lr *= 0.5e-3\n","    elif epoch > 160:\n","        lr *= 1e-3\n","    elif epoch > 120:\n","        lr *= 1e-2\n","    elif epoch > 80:\n","        lr *= 1e-1\n","    #print('Learning rate: ', lr)\n","    return lr\n","  # if epoch < 40:\n","  #   return 0.01\n","  # else:\n","  #   return 0.01 * np.math.exp(0.03 * (40 - epoch))\n","lrdecay = tf.keras.callbacks.LearningRateScheduler(lrdecay) # learning rate decay  \n","\n","\n","def earlystop(mode):\n","  if mode=='acc':\n","    estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15, mode='max')\n","  elif mode=='loss':\n","    estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min')\n","  return estop    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"LQmIe7aXyjiA"},"outputs":[],"source":["resnet50_model = resnet50()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":979,"status":"ok","timestamp":1592016369227,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"HpJ5jY391JFA","outputId":"af409e75-831e-443b-e921-acf8d35a9727"},"outputs":[],"source":["resnet50_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"vJYeyPZQ38JW"},"outputs":[],"source":["resnet50_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-3), \n","                       metrics=['acc'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":5383717,"status":"ok","timestamp":1592021760496,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"TmutGQJp54wv","outputId":"82f13e69-1776-42f7-ba57-12a8f383e9ec"},"outputs":[],"source":["batch_size=batch_size # test with 64, 128, 256\n","\n","resnet_train = resnet50_model.fit(train_set_conv, \n","                                  epochs=160, \n","                                  steps_per_epoch=train_im.shape[0]/batch_size, \n","                                  validation_steps=valid_im.shape[0]/batch_size, \n","                                  validation_data=valid_set_conv, \n","                                  callbacks=[lrdecay])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"colab_type":"code","executionInfo":{"elapsed":2524,"status":"ok","timestamp":1592022962471,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"XbziRYwD8xA_","outputId":"a3e46f1f-3c75-46e8-910a-f7c0b3fb584f"},"outputs":[],"source":["### Plot train and validation curves\n","loss = resnet_train.history['loss']\n","v_loss = resnet_train.history['val_loss']\n","\n","acc = resnet_train.history['acc']\n","v_acc = resnet_train.history['val_acc']\n","\n","epochs = range(len(loss))\n","\n","fig = plt.figure(figsize=(9, 5))\n","plt.subplot(1, 2, 1)\n","plt.yscale('log')\n","plt.plot(epochs, loss, linestyle='--', linewidth=3, color='orange', alpha=0.7, label='Train Loss')\n","plt.plot(epochs, v_loss, linestyle='-.', linewidth=2, color='lime', alpha=0.8, label='Valid Loss')\n","plt.ylim(0.3, 100)\n","plt.xlabel('Epochs', fontsize=11)\n","plt.ylabel('Loss', fontsize=12)\n","plt.legend(fontsize=12)\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, acc, linestyle='--', linewidth=3, color='orange', alpha=0.7, label='Train Acc')\n","plt.plot(epochs, v_acc, linestyle='-.', linewidth=2, color='lime', alpha=0.8, label='Valid Acc') \n","plt.xlabel('Epochs', fontsize=11)\n","plt.ylabel('Accuracy', fontsize=12)\n","plt.legend(fontsize=12)\n","plt.tight_layout()\n","plt.savefig('/content/gdrive/My Drive/Colab Notebooks/resnet/train_acc.png', dpi=250)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"colab_type":"code","executionInfo":{"elapsed":27650,"status":"ok","timestamp":1592022823220,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"cUOsl4GHzoSe","outputId":"558f55b1-a556-425f-b6b9-30f44d142eba"},"outputs":[],"source":["from google.colab import  drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":73},"colab_type":"code","executionInfo":{"elapsed":1427,"status":"ok","timestamp":1592023089900,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"Af5_vzFnEI28","outputId":"f7592cdb-e3f0-4d87-8564-00747fd74d24"},"outputs":[],"source":["#### Plot the Confusion Matrix\n","\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","\n","def conf_matrix(predictions): \n","    ''' Plots conf. matrix and classification report '''\n","    cm=confusion_matrix(test_lab, np.argmax(np.round(predictions), axis=1))\n","    print(\"Classification Report:\\n\")\n","    cr=classification_report(test_lab,\n","                                np.argmax(np.round(predictions), axis=1), \n","                                target_names=[class_types[i] for i in range(len(class_types))])\n","    print(cr)\n","    plt.figure(figsize=(12,12))\n","    sns_hmp = sns.heatmap(cm, annot=True, xticklabels = [class_types[i] for i in range(len(class_types))], \n","                yticklabels = [class_types[i] for i in range(len(class_types))], fmt=\"d\")\n","    fig = sns_hmp.get_figure()\n","    fig.savefig('/content/gdrive/My Drive/Colab Notebooks/resnet/heatmap.png', dpi=250)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"colab_type":"code","executionInfo":{"elapsed":6935,"status":"ok","timestamp":1592023099692,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"xj81pYK-zc9C","outputId":"6886e381-3a7e-4cb2-9f30-b2cb1fb96d49"},"outputs":[],"source":["pred_class_resnet50 = resnet50_model.predict(test_im)\n","\n","conf_matrix(pred_class_resnet50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"colab_type":"code","executionInfo":{"elapsed":6098,"status":"ok","timestamp":1592023127647,"user":{"displayName":"Swap vi","photoUrl":"","userId":"01936573407644251994"},"user_tz":-540},"id":"wws0OyUW0O8F","outputId":"0ed4d0b2-4a3d-4074-dcdf-e69a5dbb083c"},"outputs":[],"source":["### Resutls on Test Data; \n","## Check the performance on the test data \n","test_result = resnet50_model.evaluate(test_im, test_lab_categorical, verbose=0)\n","\n","print (\"ResNet50 loss: \", test_result[0])\n","print (\"ResNet50 accuracy: \", test_result[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{},"colab_type":"code","id":"TllMeG4N05_h"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNurwRiIAE6nnGeLPSKFYo4","collapsed_sections":[],"name":"Implement_Resnet_TensorFlow.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}
