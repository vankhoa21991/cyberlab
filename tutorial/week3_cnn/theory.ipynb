{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng lớp convolution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution bằng numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K): \n",
    "    \"\"\"Compute 2D convolution.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = np.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            # print(np.sum(X[i:i + h, j:j + w] * K))\n",
    "            Y[i, j] = np.sum(X[i:i + h, j:j + w] * K)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19., 25.],\n",
       "       [37., 43.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = np.array([[0.0, 1.0], [2.0, 3.0]])\n",
    "conv2d(X, K)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolution bằng tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[19.]\n",
      "   [25.]]\n",
      "\n",
      "  [[37.]\n",
      "   [43.]]]], shape=(1, 2, 2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K_tensor = K.reshape((2, 2, 1, 1))\n",
    "X_tensor = X.reshape((1, 3, 3, 1))\n",
    "\n",
    "conv_layer = tf.keras.layers.Conv2D(filters=1, kernel_size=(2, 2), strides=(1, 1), padding='valid', use_bias=False)\n",
    "conv_layer.build(input_shape=(None, 3, 3, 1))\n",
    "conv_layer.set_weights([K_tensor])\n",
    "\n",
    "# Apply the convolutional layer to the input tensor\n",
    "output = conv_layer(X_tensor)\n",
    "\n",
    "# Print the output of the convolutional layer\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm convolution đầy đủ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv2d(x, W, stride=1, padding=0):\n",
    "    \"\"\"\n",
    "    Performs a 2D convolution on input tensor x with filter W.\n",
    "\n",
    "    Args:\n",
    "    x: Input tensor, shape [batch, in_height, in_width, in_channels]\n",
    "    W: Filter tensor, shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    stride: Stride of the convolution in each dimension\n",
    "    padding: Padding size to apply to the input tensor\n",
    "\n",
    "    Returns:\n",
    "    A tensor of shape [batch, out_height, out_width, out_channels] containing the result\n",
    "    of the convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    batch, in_height, in_width, in_channels = x.shape\n",
    "    filter_height, filter_width, _, out_channels = W.shape\n",
    "\n",
    "    # Compute output dimensions\n",
    "    out_height = int((in_height + 2*padding - filter_height) / stride + 1)\n",
    "    out_width = int((in_width + 2*padding - filter_width) / stride + 1)\n",
    "\n",
    "    # Add padding to input tensor\n",
    "    x_padded = np.pad(x, [(0,0), (padding, padding), (padding, padding), (0,0)], mode='constant')\n",
    "\n",
    "    # Initialize output tensor\n",
    "    output = np.zeros((batch, out_height, out_width, out_channels))\n",
    "\n",
    "    # Perform convolution\n",
    "    for b in range(batch):\n",
    "        for h in range(out_height):\n",
    "            for w in range(out_width):\n",
    "                for c in range(out_channels):\n",
    "                    # Compute slice of input tensor to apply filter to\n",
    "                    h_start = h * stride\n",
    "                    h_end = h_start + filter_height\n",
    "                    w_start = w * stride\n",
    "                    w_end = w_start + filter_width\n",
    "                    x_slice = x_padded[b, h_start:h_end, w_start:w_end, :]\n",
    "\n",
    "                    # Apply filter to input slice\n",
    "                    output[b, h, w, c] = np.sum(x_slice * W[:, :, :, c])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.],\n",
       "         [ 3.],\n",
       "         [ 8.],\n",
       "         [ 4.]],\n",
       "\n",
       "        [[ 9.],\n",
       "         [19.],\n",
       "         [25.],\n",
       "         [10.]],\n",
       "\n",
       "        [[21.],\n",
       "         [37.],\n",
       "         [43.],\n",
       "         [16.]],\n",
       "\n",
       "        [[ 6.],\n",
       "         [ 7.],\n",
       "         [ 8.],\n",
       "         [ 0.]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(X_tensor, K_tensor, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[19.]\n",
      "   [25.]\n",
      "   [10.]]\n",
      "\n",
      "  [[37.]\n",
      "   [43.]\n",
      "   [16.]]\n",
      "\n",
      "  [[ 7.]\n",
      "   [ 8.]\n",
      "   [ 0.]]]], shape=(1, 3, 3, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "# tf.keras.layers.ZeroPadding2D(padding=(1, 1)),\n",
    "tf.keras.layers.Conv2D(filters=1, kernel_size=(2, 2), strides=(1, 1), padding='same', use_bias=False, kernel_initializer=tf.keras.initializers.Constant(K_tensor))\n",
    "])\n",
    "\n",
    "# Apply the convolutional layer to the input tensor\n",
    "output = model(X_tensor)\n",
    "\n",
    "# Print the output of the convolutional layer\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lớp pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[4.]\n",
      "   [5.]]\n",
      "\n",
      "  [[7.]\n",
      "   [8.]]]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "pooling_layer = MaxPooling2D(pool_size=(2, 2), strides=(1, 1))\n",
    "output_tensor = pooling_layer(X_tensor)\n",
    "\n",
    "# Print the output tensor\n",
    "print(output_tensor.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xây dựng mô hình cho MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.1974 - accuracy: 0.9422 - val_loss: 0.0628 - val_accuracy: 0.9803\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0523 - accuracy: 0.9835 - val_loss: 0.0434 - val_accuracy: 0.9851\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0373 - accuracy: 0.9884 - val_loss: 0.0525 - val_accuracy: 0.9825\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.0303 - val_accuracy: 0.9902\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 27s 58ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0292 - val_accuracy: 0.9911\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0337 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0140 - accuracy: 0.9957 - val_loss: 0.0267 - val_accuracy: 0.9916\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0292 - val_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0287 - val_accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0296 - val_accuracy: 0.9912\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0296 - accuracy: 0.9912\n",
      "Test accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1) / 255.0\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBatchNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, momentum=0.99, epsilon=1e-5, **kwargs):\n",
    "        super(CustomBatchNormalization, self).__init__(**kwargs)\n",
    "        self.momentum = momentum\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Initialize trainable variables\n",
    "        self.gamma = self.add_weight(name='gamma', shape=(input_shape[-1],),\n",
    "                                     initializer='ones', trainable=True)\n",
    "        self.beta = self.add_weight(name='beta', shape=(input_shape[-1],),\n",
    "                                    initializer='zeros', trainable=True)\n",
    "        self.running_mean = self.add_weight(name='running_mean', shape=(input_shape[-1],),\n",
    "                                            initializer='zeros', trainable=False)\n",
    "        self.running_var = self.add_weight(name='running_var', shape=(input_shape[-1],),\n",
    "                                           initializer='ones', trainable=False)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Calculate mean and variance across batch\n",
    "        mean, variance = tf.nn.moments(inputs, axes=[0, 1, 2])\n",
    "\n",
    "        # Update running mean and variance during training\n",
    "        if training:\n",
    "            self.running_mean.assign(self.momentum * self.running_mean + (1.0 - self.momentum) * mean)\n",
    "            self.running_var.assign(self.momentum * self.running_var + (1.0 - self.momentum) * variance)\n",
    "\n",
    "        # Normalize inputs\n",
    "        normalized = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
    "\n",
    "        # Apply scale and offset\n",
    "        output = self.gamma * normalized + self.beta\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build the model ResNet50 https://towardsdatascience.com/understand-and-implement-resnet-50-with-tensorflow-2-0-1190b9b52691"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Compute CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K): \n",
    "    \"\"\"Compute 2D convolution.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "conv2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Su dung 1 kernel nhu la mot edge detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0, -1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = conv2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Huan luyen kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 9.717\n",
      "epoch 4, loss 1.705\n",
      "epoch 6, loss 0.317\n",
      "epoch 8, loss 0.066\n",
      "epoch 10, loss 0.016\n"
     ]
    }
   ],
   "source": [
    "# Construct a two-dimensional convolutional layer with 1 output channel and a\n",
    "# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n",
    "conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n",
    "\n",
    "# The two-dimensional convolutional layer uses four-dimensional input and\n",
    "# output in the format of (example, channel, height, width), where the batch\n",
    "# size (number of examples in the batch) and the number of channels are both 1\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "lr = 3e-2  # Learning rate\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    # Update the kernel\n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    if (i + 1) % 2 == 0:\n",
    "        print(f'epoch {i + 1}, loss {l.sum():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9937, -0.9744]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel duoc hoc nay tien gan voi kernel K dinh san o tren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Max va average pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2, 2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Them padding va stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X + 1), 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cac mo hinh CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: dung pretrained model on mnist to run inference"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5980b3a08a94ca7d4924634a4e2ea7a5238b35723e0e305f23d28d43ee7ce05"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
