{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Self Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, torch.arange(\n",
    "            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim, num_steps = 32, 60\n",
    "pos_encoding = PositionalEncoding(encoding_dim, 0)\n",
    "X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))\n",
    "P = pos_encoding.P[:, :X.shape[1], :]\n",
    "# d2l.plot(torch.arange(num_steps), P[0, :, 6:10].T, xlabel='Row (position)',\n",
    "#          figsize=(6, 2.5), legend=[\"Col %d\" % d for d in torch.arange(6, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n",
    "                  cmap='Reds'):\n",
    "    \"\"\"Show heatmaps of matrices.\n",
    "\n",
    "    Defined in :numref:`sec_attention-cues`\"\"\"\n",
    "    num_rows, num_cols = matrices.shape[0], matrices.shape[1]\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize,\n",
    "                                 sharex=True, sharey=True, squeeze=False)\n",
    "    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n",
    "        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n",
    "            pcm = ax.imshow(matrix.detach().numpy(), cmap=cmap)\n",
    "            if i == num_rows - 1:\n",
    "                ax.set_xlabel(xlabel)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(ylabel)\n",
    "            if titles:\n",
    "                ax.set_title(titles[j])\n",
    "    fig.colorbar(pcm, ax=axes, shrink=0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "P = P[0, :, :].unsqueeze(0).unsqueeze(0)\n",
    "show_heatmaps(P, xlabel='Column (encoding dimension)',\n",
    "                  ylabel='Row (position)', figsize=(16, 5), cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    \"\"\"Mask irrelevant entries in sequences.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_lens):\n",
    "    \"\"\"Perform softmax operation by masking elements on the last axis.\n",
    "\n",
    "    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n",
    "    # `X`: 3D tensor, `valid_lens`: 1D or 2D tensor\n",
    "    if valid_lens is None:\n",
    "        return nn.functional.softmax(X, dim=-1)\n",
    "    else:\n",
    "        shape = X.shape\n",
    "        if valid_lens.dim() == 1:\n",
    "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
    "        else:\n",
    "            valid_lens = valid_lens.reshape(-1)\n",
    "        # On the last axis, replace masked elements with a very large negative\n",
    "        # value, whose exponentiation outputs 0\n",
    "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens,\n",
    "                              value=-1e6)\n",
    "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):\n",
    "    \"\"\"Scaled dot product attention.\n",
    "\n",
    "    Defined in :numref:`subsec_additive-attention`\"\"\"\n",
    "    def __init__(self, dropout, **kwargs):\n",
    "        super(DotProductAttention, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Shape of `queries`: (`batch_size`, no. of queries, `d`)\n",
    "    # Shape of `keys`: (`batch_size`, no. of key-value pairs, `d`)\n",
    "    # Shape of `values`: (`batch_size`, no. of key-value pairs, value\n",
    "    # dimension)\n",
    "    # Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        d = queries.shape[-1]\n",
    "        # Set `transpose_b=True` to swap the last two dimensions of `keys`\n",
    "        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                    num_heads, dropout, bias=False, **kwargs):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = DotProductAttention(dropout)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n",
    "        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n",
    "        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        queries = utils.transpose_qkv(self.W_q(queries), self.num_heads)\n",
    "        keys = utils.transpose_qkv(self.W_k(keys), self.num_heads)\n",
    "        values = utils.transpose_qkv(self.W_v(values), self.num_heads)\n",
    "\n",
    "        if valid_lens is not None:\n",
    "            # On axis 0, copy the first item (scalar or vector) for\n",
    "            # `num_heads` times, then copy the next item, and so on\n",
    "            valid_lens = torch.repeat_interleave(\n",
    "                valid_lens, repeats=self.num_heads, dim=0)\n",
    "\n",
    "        # Shape of `output`: (`batch_size` * `num_heads`, no. of queries,\n",
    "        # `num_hiddens` / `num_heads`)\n",
    "        output = self.attention(queries, keys, values, valid_lens)\n",
    "\n",
    "        # Shape of `output_concat`:\n",
    "        # (`batch_size`, no. of queries, `num_hiddens`)\n",
    "        output_concat = utils.transpose_output(output, self.num_heads)\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    \"\"\"Positionwise feed-forward network.\n",
    "\n",
    "    Defined in :numref:`sec_transformer`\"\"\"\n",
    "    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs,\n",
    "                 **kwargs):\n",
    "        super(PositionWiseFFN, self).__init__(**kwargs)\n",
    "        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    \"\"\"Residual connection followed by layer normalization.\n",
    "\n",
    "    Defined in :numref:`sec_transformer`\"\"\"\n",
    "    def __init__(self, normalized_shape, dropout, **kwargs):\n",
    "        super(AddNorm, self).__init__(**kwargs)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(normalized_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5773,  0.5773, -1.7320,  0.5773],\n",
       "         [-0.5773, -0.5773,  1.7320, -0.5773],\n",
       "         [ 1.0000,  1.0000, -1.0000, -1.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.5773,  1.7320, -0.5773, -0.5773],\n",
       "         [ 0.5773,  0.5773,  0.5773, -1.7320]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm(4, 0.5)\n",
    "add_norm(torch.ones((2, 3, 4)), torch.ones((2, 3, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, use_bias=False, **kwargs):\n",
    "        super(EncoderBlock, self).__init__(**kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n",
    "            use_bias)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(\n",
    "            ffn_num_input, ffn_num_hiddens, num_hiddens)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, valid_lens):\n",
    "        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n",
    "        return self.addnorm2(Y, self.ffn(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((2, 100, 24))\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\n",
    "encoder_blk.eval()\n",
    "encoder_blk(X, valid_lens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@save\n",
    "class TransformerEncoder(utils.Encoder):\n",
    "    \"\"\"Transformer encoder.\"\"\"\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, use_bias=False, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, use_bias))\n",
    "\n",
    "    def forward(self, X, valid_lens, *args):\n",
    "        # Since positional encoding values are between -1 and 1, the embedding\n",
    "        # values are multiplied by the square root of the embedding dimension\n",
    "        # to rescale before they are summed up\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self.attention_weights = [None] * len(self.blks)\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X = blk(X, valid_lens)\n",
    "            self.attention_weights[\n",
    "                i] = blk.attention.attention.attention_weights\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoder(\n",
    "    200, 24, 24, 24, 24, [100, 24], 24, 48, 8, 2, 0.5)\n",
    "encoder.eval()\n",
    "encoder(torch.ones((2, 100), dtype=torch.long), valid_lens).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    # The `i`-th block in the decoder\n",
    "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
    "                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "                 dropout, i, **kwargs):\n",
    "        super(DecoderBlock, self).__init__(**kwargs)\n",
    "        self.i = i\n",
    "        self.attention1 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm1 = AddNorm(norm_shape, dropout)\n",
    "        self.attention2 = MultiHeadAttention(\n",
    "            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n",
    "        self.addnorm2 = AddNorm(norm_shape, dropout)\n",
    "        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens,\n",
    "                                   num_hiddens)\n",
    "        self.addnorm3 = AddNorm(norm_shape, dropout)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        enc_outputs, enc_valid_lens = state[0], state[1]\n",
    "        # During training, all the tokens of any output sequence are processed\n",
    "        # at the same time, so `state[2][self.i]` is `None` as initialized.\n",
    "        # When decoding any output sequence token by token during prediction,\n",
    "        # `state[2][self.i]` contains representations of the decoded output at\n",
    "        # the `i`-th block up to the current time step\n",
    "        if state[2][self.i] is None:\n",
    "            key_values = X\n",
    "        else:\n",
    "            key_values = torch.cat((state[2][self.i], X), axis=1)\n",
    "        state[2][self.i] = key_values\n",
    "        if self.training:\n",
    "            batch_size, num_steps, _ = X.shape\n",
    "            # Shape of `dec_valid_lens`: (`batch_size`, `num_steps`), where\n",
    "            # every row is [1, 2, ..., `num_steps`]\n",
    "            dec_valid_lens = torch.arange(\n",
    "                1, num_steps + 1, device=X.device).repeat(batch_size, 1)\n",
    "        else:\n",
    "            dec_valid_lens = None\n",
    "\n",
    "        # Self-attention\n",
    "        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n",
    "        Y = self.addnorm1(X, X2)\n",
    "        # Encoder-decoder attention. Shape of `enc_outputs`:\n",
    "        # (`batch_size`, `num_steps`, `num_hiddens`)\n",
    "        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n",
    "        Z = self.addnorm2(Y, Y2)\n",
    "        return self.addnorm3(Z, self.ffn(Z)), state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100, 24])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\n",
    "decoder_blk.eval()\n",
    "X = torch.ones((2, 100, 24))\n",
    "state = [encoder_blk(X, valid_lens), valid_lens, [None]]\n",
    "decoder_blk(X, state)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(utils.AttentionDecoder):\n",
    "    def __init__(self, vocab_size, key_size, query_size, value_size,\n",
    "                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                 num_heads, num_layers, dropout, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n",
    "        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)\n",
    "        self.blks = nn.Sequential()\n",
    "        for i in range(num_layers):\n",
    "            self.blks.add_module(\"block\"+str(i),\n",
    "                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n",
    "                             norm_shape, ffn_num_input, ffn_num_hiddens,\n",
    "                             num_heads, dropout, i))\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
    "        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n",
    "        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n",
    "        for i, blk in enumerate(self.blks):\n",
    "            X, state = blk(X, state)\n",
    "            # Decoder self-attention weights\n",
    "            self._attention_weights[0][\n",
    "                i] = blk.attention1.attention.attention_weights\n",
    "            # Encoder-decoder attention weights\n",
    "            self._attention_weights[1][\n",
    "                i] = blk.attention2.attention.attention_weights\n",
    "        return self.dense(X), state\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
    "    # `label` shape: (`batch_size`, `num_steps`)\n",
    "    # `valid_len` shape: (`batch_size`,)\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\fra-eng.zip from http://d2l-data.s3-accelerate.amazonaws.com/fra-eng.zip...\n"
     ]
    }
   ],
   "source": [
    "num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\n",
    "lr, num_epochs, device = 0.005, 200, 'cuda:0'\n",
    "ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\n",
    "key_size, query_size, value_size = 32, 32, 32\n",
    "norm_shape = [32]\n",
    "\n",
    "train_iter, src_vocab, tgt_vocab = utils.load_data_nmt(batch_size, num_steps)\n",
    "\n",
    "encoder = TransformerEncoder(\n",
    "    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "decoder = TransformerDecoder(\n",
    "    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout)\n",
    "net = utils.EncoderDecoder(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    \"\"\"Train a model for sequence to sequence.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    # animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "    #                         xlim=[10, num_epochs])\n",
    "    epochs = []\n",
    "    metrics = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # timer = d2l.Timer()\n",
    "        tik = time.time()\n",
    "        # metric = d2l.Accumulator(2)  # Sum of training loss, no. of tokens\n",
    "        metric = [0.0] * 2  # Sum of training loss, no. of tokens\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()  # Make the loss scalar for `backward`\n",
    "            utils.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                # metric.add(l.sum(), num_tokens)\n",
    "                metric = [a + float(b) for a, b in zip(metric, (l.sum(), num_tokens))]\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            # animator.add(epoch + 1, (metric[0] / metric[1],))\n",
    "            epochs.append(epoch+1)\n",
    "            metrics.append(metric[0] / metric[1])\n",
    "\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / (time.time()-tik):.1f} '\n",
    "          f'tokens/sec on {str(device)}')\n",
    "    \n",
    "    fig, axes = plt.subplots()\n",
    "    axes.plot(epochs, metrics)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.030, 8149.1 tokens/sec on cuda:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    \"\"\"Predict for sequence to sequence.\n",
    "\n",
    "    Defined in :numref:`sec_seq2seq_training`\"\"\"\n",
    "    # Set `net` to eval mode for inference\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = utils.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    # Add the batch axis\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    # Add the batch axis\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        # We use the token with the highest prediction likelihood as the input\n",
    "        # of the decoder at the next time step\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        # Once the end-of-sequence token is predicted, the generation of the\n",
    "        # output sequence is complete\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go . => va !\n",
      "i lost . => j'ai perdu .\n",
      "he's calm . => il est calme .\n",
      "i'm home . => je suis chez moi .\n"
     ]
    }
   ],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n",
    "for eng, fra in zip(engs, fras):\n",
    "    translation, dec_attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n",
    "    print(f'{eng} => {translation}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5980b3a08a94ca7d4924634a4e2ea7a5238b35723e0e305f23d28d43ee7ce05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
